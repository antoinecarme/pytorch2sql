{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "from sklearn import datasets\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import skorch\n",
    "from skorch import NeuralNetClassifier\n",
    "\n",
    "torch.manual_seed(1960)\n",
    "\n",
    "torch.set_default_tensor_type('torch.DoubleTensor')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build a PyTorch Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for the moment, only experimenting with pytorch sequential models, \n",
    "# This is a limitation and we will try to see what can be made to make\n",
    "# recurrent layers and convolutions usable inside sequential models.\n",
    "# Functional models (with custom forward methods) (are not/will not be) supported anyway.\n",
    "\n",
    "\n",
    "# This is a toy regression model with one hidden layer, a dropout, a relu and softmax.\n",
    "def create_model():\n",
    "    hidden_units = 15\n",
    "    num_classes = 3\n",
    "    num_inputs = 4\n",
    "    model = nn.Sequential(\n",
    "        nn.Linear(num_inputs, hidden_units),\n",
    "        nn.ReLU(),\n",
    "        nn.Dropout(),\n",
    "        nn.Linear(hidden_units , num_classes),\n",
    "        nn.Softmax())\n",
    "\n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris  = datasets.load_iris()\n",
    "train_X, test_X, train_y, test_y = train_test_split(iris.data, iris.target, train_size=0.8, test_size=0.2, random_state=1960)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(120, 4) (120,)\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m1.5288\u001b[0m       \u001b[32m0.4400\u001b[0m        \u001b[35m1.1225\u001b[0m  0.0088\n",
      "      2        1.6762       \u001b[32m0.6800\u001b[0m        \u001b[35m1.0600\u001b[0m  0.0036\n",
      "      3        \u001b[36m1.3265\u001b[0m       0.6800        \u001b[35m1.0128\u001b[0m  0.0037\n",
      "      4        \u001b[36m1.2542\u001b[0m       0.6800        \u001b[35m0.9807\u001b[0m  0.0036\n",
      "      5        \u001b[36m1.1924\u001b[0m       0.6800        \u001b[35m0.9628\u001b[0m  0.0034\n",
      "      6        \u001b[36m1.1623\u001b[0m       0.6800        \u001b[35m0.9529\u001b[0m  0.0033\n",
      "      7        \u001b[36m1.1261\u001b[0m       0.6800        \u001b[35m0.9481\u001b[0m  0.0032\n",
      "      8        \u001b[36m0.9808\u001b[0m       0.4400        \u001b[35m0.9450\u001b[0m  0.0034\n",
      "      9        1.0291       0.6000        \u001b[35m0.9421\u001b[0m  0.0033\n",
      "     10        \u001b[36m0.9788\u001b[0m       0.6400        \u001b[35m0.9381\u001b[0m  0.0034\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/antoine/.local/lib/python3.6/site-packages/torch/nn/modules/container.py:91: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  input = module(input)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<class 'skorch.classifier.NeuralNetClassifier'>[initialized](\n",
       "  module_=Sequential(\n",
       "    (0): Linear(in_features=4, out_features=15, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Dropout(p=0.5)\n",
       "    (3): Linear(in_features=15, out_features=3, bias=True)\n",
       "    (4): Softmax()\n",
       "  ),\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "net = skorch.NeuralNetClassifier(\n",
    "    create_model(),\n",
    "    optimizer=torch.optim.Adam,\n",
    "    max_epochs=10,\n",
    ")\n",
    "\n",
    "\n",
    "print(train_X.shape , train_y.shape)\n",
    "net.fit(train_X, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'module': Sequential(\n",
      "  (0): Linear(in_features=4, out_features=15, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Dropout(p=0.5)\n",
      "  (3): Linear(in_features=15, out_features=3, bias=True)\n",
      "  (4): Softmax()\n",
      "), 'criterion': <class 'torch.nn.modules.loss.NLLLoss'>, 'optimizer': <class 'torch.optim.adam.Adam'>, 'lr': 0.01, 'max_epochs': 10, 'batch_size': 128, 'iterator_train': <class 'torch.utils.data.dataloader.DataLoader'>, 'iterator_valid': <class 'torch.utils.data.dataloader.DataLoader'>, 'dataset': <class 'skorch.dataset.Dataset'>, 'train_split': <skorch.dataset.CVSplit object at 0x7fb3985b9630>, 'callbacks': None, 'warm_start': False, 'verbose': 1, 'device': 'cpu', 'history': [{'batches': [{'train_loss': 1.528769080349241, 'train_batch_size': 95}, {'valid_loss': 1.1224694415289365, 'valid_batch_size': 25}], 'epoch': 1, 'dur': 0.008803844451904297, 'train_loss': 1.528769080349241, 'train_loss_best': True, 'valid_loss': 1.1224694415289365, 'valid_loss_best': True, 'valid_acc': 0.44, 'valid_acc_best': True}, {'batches': [{'train_loss': 1.676197399528274, 'train_batch_size': 95}, {'valid_loss': 1.060030800715479, 'valid_batch_size': 25}], 'epoch': 2, 'dur': 0.0036122798919677734, 'train_loss': 1.676197399528274, 'train_loss_best': False, 'valid_loss': 1.060030800715479, 'valid_loss_best': True, 'valid_acc': 0.68, 'valid_acc_best': True}, {'batches': [{'train_loss': 1.3265482605591958, 'train_batch_size': 95}, {'valid_loss': 1.0127735829212725, 'valid_batch_size': 25}], 'epoch': 3, 'dur': 0.003723621368408203, 'train_loss': 1.3265482605591958, 'train_loss_best': True, 'valid_loss': 1.0127735829212725, 'valid_loss_best': True, 'valid_acc': 0.68, 'valid_acc_best': False}, {'batches': [{'train_loss': 1.2541550298070994, 'train_batch_size': 95}, {'valid_loss': 0.9806911974064387, 'valid_batch_size': 25}], 'epoch': 4, 'dur': 0.0036356449127197266, 'train_loss': 1.2541550298070994, 'train_loss_best': True, 'valid_loss': 0.9806911974064387, 'valid_loss_best': True, 'valid_acc': 0.68, 'valid_acc_best': False}, {'batches': [{'train_loss': 1.1923763884690908, 'train_batch_size': 95}, {'valid_loss': 0.9627616593376891, 'valid_batch_size': 25}], 'epoch': 5, 'dur': 0.0034008026123046875, 'train_loss': 1.1923763884690908, 'train_loss_best': True, 'valid_loss': 0.9627616593376891, 'valid_loss_best': True, 'valid_acc': 0.68, 'valid_acc_best': False}, {'batches': [{'train_loss': 1.162333083901162, 'train_batch_size': 95}, {'valid_loss': 0.9529006403561141, 'valid_batch_size': 25}], 'epoch': 6, 'dur': 0.003278017044067383, 'train_loss': 1.162333083901162, 'train_loss_best': True, 'valid_loss': 0.9529006403561141, 'valid_loss_best': True, 'valid_acc': 0.68, 'valid_acc_best': False}, {'batches': [{'train_loss': 1.1261362061108724, 'train_batch_size': 95}, {'valid_loss': 0.9480514199452047, 'valid_batch_size': 25}], 'epoch': 7, 'dur': 0.003161907196044922, 'train_loss': 1.1261362061108724, 'train_loss_best': True, 'valid_loss': 0.9480514199452047, 'valid_loss_best': True, 'valid_acc': 0.68, 'valid_acc_best': False}, {'batches': [{'train_loss': 0.9808492226504415, 'train_batch_size': 95}, {'valid_loss': 0.945003113489696, 'valid_batch_size': 25}], 'epoch': 8, 'dur': 0.003363370895385742, 'train_loss': 0.9808492226504415, 'train_loss_best': True, 'valid_loss': 0.945003113489696, 'valid_loss_best': True, 'valid_acc': 0.44, 'valid_acc_best': False}, {'batches': [{'train_loss': 1.0291050511405269, 'train_batch_size': 95}, {'valid_loss': 0.9421019648995813, 'valid_batch_size': 25}], 'epoch': 9, 'dur': 0.0033185482025146484, 'train_loss': 1.0291050511405269, 'train_loss_best': False, 'valid_loss': 0.9421019648995813, 'valid_loss_best': True, 'valid_acc': 0.6, 'valid_acc_best': False}, {'batches': [{'train_loss': 0.9788184802682794, 'train_batch_size': 95}, {'valid_loss': 0.9380652363367256, 'valid_batch_size': 25}], 'epoch': 10, 'dur': 0.003401041030883789, 'train_loss': 0.9788184802682794, 'train_loss_best': True, 'valid_loss': 0.9380652363367256, 'valid_loss_best': True, 'valid_acc': 0.64, 'valid_acc_best': False}], 'initialized_': True, 'callbacks_': [('epoch_timer', <skorch.callbacks.logging.EpochTimer object at 0x7fb3986d34a8>), ('train_loss', <skorch.callbacks.scoring.BatchScoring object at 0x7fb3986d3898>), ('valid_loss', <skorch.callbacks.scoring.BatchScoring object at 0x7fb3986d3cf8>), ('valid_acc', <skorch.callbacks.scoring.EpochScoring object at 0x7fb3986d37b8>), ('print_log', <skorch.callbacks.logging.PrintLog object at 0x7fb3986d3748>)], 'criterion_': NLLLoss(), 'module_': Sequential(\n",
      "  (0): Linear(in_features=4, out_features=15, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Dropout(p=0.5)\n",
      "  (3): Linear(in_features=15, out_features=3, bias=True)\n",
      "  (4): Softmax()\n",
      "), 'optimizer_': Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    eps: 1e-08\n",
      "    lr: 0.01\n",
      "    weight_decay: 0\n",
      ")}\n"
     ]
    }
   ],
   "source": [
    "print(net.__dict__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30, 4)\n",
      "[[0.18185966 0.45338441 0.36475593]]\n"
     ]
    }
   ],
   "source": [
    "print(test_X.shape)\n",
    "preds = net.predict_proba(test_X[0,:].reshape(1,4))\n",
    "print(preds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate SQL Code from the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json, requests, base64, pickle, sys\n",
    "\n",
    "sys.setrecursionlimit(200000)\n",
    "\n",
    "# Pickle the model and send it to the SQL generation web service\n",
    "# Get back the  SQL code.\n",
    "def test_ws_sql_gen(pickle_data):\n",
    "    WS_URL=\"http://localhost:1888/model\"\n",
    "    b64_data = base64.b64encode(pickle_data).decode('utf-8')\n",
    "    data={\"Name\":\"model1\", \"PickleData\":b64_data , \"SQLDialect\":\"postgresql\"}\n",
    "    r = requests.post(WS_URL, json=data)\n",
    "    # print(r.__dict__)\n",
    "    content = r.json()\n",
    "    # print(content)\n",
    "    lSQL = content[\"model\"][\"SQLGenrationResult\"][0][\"SQL\"]\n",
    "    return lSQL;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle_data = pickle.dumps(net)\n",
    "lSQL = test_ws_sql_gen(pickle_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WITH pytorch_input AS \n",
      "(SELECT \"ADS\".\"KEY\" AS \"KEY\", \"ADS\".\"Feature_0\" AS \"Feature_0\", \"ADS\".\"Feature_1\" AS \"Feature_1\", \"ADS\".\"Feature_2\" AS \"Feature_2\", \"ADS\".\"Feature_3\" AS \"Feature_3\" \n",
      "FROM \"INPUT_DATA\" AS \"ADS\"), \n",
      "pytorch_input_1 AS \n",
      "(SELECT pytorch_input.\"KEY\" AS \"KEY\", pytorch_input.\"Feature_0\" AS \"Feature_0\", pytorch_input.\"Feature_1\" AS \"Feature_1\", pytorch_input.\"Feature_2\" AS \"Feature_2\", pytorch_input.\"Feature_3\" AS \"Feature_3\" \n",
      "FROM pytorch_input), \n",
      "layer_0 AS \n",
      "(SELECT pytorch_input_1.\"KEY\" AS \"KEY\", 0.26364428222521186 + -0.3508236420356722 * pytorch_input_1.\"Feature_0\" + -0.17123968666518297 * pytorch_input_1.\"Feature_1\" + -0.13823569361080223 * pytorch_input_1.\"Feature_2\" + 0.47668015286731624 * pytorch_input_1.\"Feature_3\" AS output_1, -0.3482905109501817 + 0.12509916834672533 * pytorch_input_1.\"Feature_0\" + -0.21371471020834162 * pytorch_input_1.\"Feature_1\" + 0.42256442335314226 * pytorch_input_1.\"Feature_2\" + -0.39076505831131364 * pytorch_input_1.\"Feature_3\" AS output_2, -0.3552401510878068 + 0.10861761589815833 * pytorch_input_1.\"Feature_0\" + -0.39909514721791084 * pytorch_input_1.\"Feature_1\" + -0.42107359314264037 * pytorch_input_1.\"Feature_2\" + 0.18259109466075252 * pytorch_input_1.\"Feature_3\" AS output_3, 0.33821106244486776 + -0.12450368567132841 * pytorch_input_1.\"Feature_0\" + 0.4108973756168854 * pytorch_input_1.\"Feature_1\" + 0.0670267592594347 * pytorch_input_1.\"Feature_2\" + -0.06670399607920727 * pytorch_input_1.\"Feature_3\" AS output_4, 0.3607333703409943 + -0.3042087280266006 * pytorch_input_1.\"Feature_0\" + -0.07705858464810722 * pytorch_input_1.\"Feature_1\" + -0.09707295662561055 * pytorch_input_1.\"Feature_2\" + 0.1774495484628832 * pytorch_input_1.\"Feature_3\" AS output_5, 0.1787169365652448 + 0.19079495843084215 * pytorch_input_1.\"Feature_0\" + 0.354811862298964 * pytorch_input_1.\"Feature_1\" + 0.1546688368083413 * pytorch_input_1.\"Feature_2\" + -0.08038493461201282 * pytorch_input_1.\"Feature_3\" AS output_6, -0.4815240114940258 + -0.1256143573588845 * pytorch_input_1.\"Feature_0\" + -0.3105264695469221 * pytorch_input_1.\"Feature_1\" + -0.26214683502842373 * pytorch_input_1.\"Feature_2\" + -0.46309329741814576 * pytorch_input_1.\"Feature_3\" AS output_7, -0.28800100135846785 + -0.14512035612667284 * pytorch_input_1.\"Feature_0\" + 0.08204550038070901 * pytorch_input_1.\"Feature_1\" + 0.24184276724108655 * pytorch_input_1.\"Feature_2\" + -0.3400697100885761 * pytorch_input_1.\"Feature_3\" AS output_8, -0.4122537312647233 + 0.2847835775204287 * pytorch_input_1.\"Feature_0\" + -0.16247257994484363 * pytorch_input_1.\"Feature_1\" + -0.06185347445481934 * pytorch_input_1.\"Feature_2\" + 0.5376866072718683 * pytorch_input_1.\"Feature_3\" AS output_9, -0.19080457635797843 + -0.14591304382670078 * pytorch_input_1.\"Feature_0\" + -0.14114919649691238 * pytorch_input_1.\"Feature_1\" + -0.14526847265548293 * pytorch_input_1.\"Feature_2\" + 0.01932793212002437 * pytorch_input_1.\"Feature_3\" AS output_10, -0.17703889553357854 + -0.22768749918743303 * pytorch_input_1.\"Feature_0\" + -0.31156309863494436 * pytorch_input_1.\"Feature_1\" + -0.26348347478276635 * pytorch_input_1.\"Feature_2\" + -0.44491976211084105 * pytorch_input_1.\"Feature_3\" AS output_11, 0.23374695567792964 + 0.19130475243624673 * pytorch_input_1.\"Feature_0\" + 0.3663862436735481 * pytorch_input_1.\"Feature_1\" + -0.39660309306502567 * pytorch_input_1.\"Feature_2\" + 0.34294028218773076 * pytorch_input_1.\"Feature_3\" AS output_12, 0.4445225405296573 + 0.3152870630509873 * pytorch_input_1.\"Feature_0\" + -0.11219155052617359 * pytorch_input_1.\"Feature_1\" + -0.4548598850477627 * pytorch_input_1.\"Feature_2\" + -0.28700382781623784 * pytorch_input_1.\"Feature_3\" AS output_13, -0.133304250704403 + -0.31062004934179377 * pytorch_input_1.\"Feature_0\" + -0.282445586699304 * pytorch_input_1.\"Feature_1\" + -0.275795129791617 * pytorch_input_1.\"Feature_2\" + 0.027718582331428654 * pytorch_input_1.\"Feature_3\" AS output_14, -0.43092377199768395 + 0.15859958402475616 * pytorch_input_1.\"Feature_0\" + -0.45028607178652935 * pytorch_input_1.\"Feature_1\" + -0.4812464895699483 * pytorch_input_1.\"Feature_2\" + -0.08497872071906587 * pytorch_input_1.\"Feature_3\" AS output_15 \n",
      "FROM pytorch_input_1), \n",
      "layer_0_1 AS \n",
      "(SELECT layer_0.\"KEY\" AS \"KEY\", layer_0.output_1 AS output_1, layer_0.output_2 AS output_2, layer_0.output_3 AS output_3, layer_0.output_4 AS output_4, layer_0.output_5 AS output_5, layer_0.output_6 AS output_6, layer_0.output_7 AS output_7, layer_0.output_8 AS output_8, layer_0.output_9 AS output_9, layer_0.output_10 AS output_10, layer_0.output_11 AS output_11, layer_0.output_12 AS output_12, layer_0.output_13 AS output_13, layer_0.output_14 AS output_14, layer_0.output_15 AS output_15 \n",
      "FROM layer_0), \n",
      "activation_relu AS \n",
      "(SELECT layer_0_1.\"KEY\" AS \"KEY\", greatest(layer_0_1.output_1, 0) AS output_1, greatest(layer_0_1.output_2, 0) AS output_2, greatest(layer_0_1.output_3, 0) AS output_3, greatest(layer_0_1.output_4, 0) AS output_4, greatest(layer_0_1.output_5, 0) AS output_5, greatest(layer_0_1.output_6, 0) AS output_6, greatest(layer_0_1.output_7, 0) AS output_7, greatest(layer_0_1.output_8, 0) AS output_8, greatest(layer_0_1.output_9, 0) AS output_9, greatest(layer_0_1.output_10, 0) AS output_10, greatest(layer_0_1.output_11, 0) AS output_11, greatest(layer_0_1.output_12, 0) AS output_12, greatest(layer_0_1.output_13, 0) AS output_13, greatest(layer_0_1.output_14, 0) AS output_14, greatest(layer_0_1.output_15, 0) AS output_15 \n",
      "FROM layer_0_1), \n",
      "activation_relu_1 AS \n",
      "(SELECT activation_relu.\"KEY\" AS \"KEY\", activation_relu.output_1 AS output_1, activation_relu.output_2 AS output_2, activation_relu.output_3 AS output_3, activation_relu.output_4 AS output_4, activation_relu.output_5 AS output_5, activation_relu.output_6 AS output_6, activation_relu.output_7 AS output_7, activation_relu.output_8 AS output_8, activation_relu.output_9 AS output_9, activation_relu.output_10 AS output_10, activation_relu.output_11 AS output_11, activation_relu.output_12 AS output_12, activation_relu.output_13 AS output_13, activation_relu.output_14 AS output_14, activation_relu.output_15 AS output_15 \n",
      "FROM activation_relu), \n",
      "activation_relu_1_1 AS \n",
      "(SELECT activation_relu_1.\"KEY\" AS \"KEY\", activation_relu_1.output_1 AS output_1, activation_relu_1.output_2 AS output_2, activation_relu_1.output_3 AS output_3, activation_relu_1.output_4 AS output_4, activation_relu_1.output_5 AS output_5, activation_relu_1.output_6 AS output_6, activation_relu_1.output_7 AS output_7, activation_relu_1.output_8 AS output_8, activation_relu_1.output_9 AS output_9, activation_relu_1.output_10 AS output_10, activation_relu_1.output_11 AS output_11, activation_relu_1.output_12 AS output_12, activation_relu_1.output_13 AS output_13, activation_relu_1.output_14 AS output_14, activation_relu_1.output_15 AS output_15 \n",
      "FROM activation_relu_1), \n",
      "layer_3 AS \n",
      "(SELECT activation_relu_1_1.\"KEY\" AS \"KEY\", 0.10940266468345942 + 0.19106466511991044 * activation_relu_1_1.output_1 + 0.10082267701708858 * activation_relu_1_1.output_2 + -0.2015845585499118 * activation_relu_1_1.output_3 + 0.09354655279145165 * activation_relu_1_1.output_4 + -0.23046863486611094 * activation_relu_1_1.output_5 + -0.1972792100006187 * activation_relu_1_1.output_6 + 0.0726038485722642 * activation_relu_1_1.output_7 + 0.0186424018658205 * activation_relu_1_1.output_8 + -0.2517466664287549 * activation_relu_1_1.output_9 + 0.01759137644918618 * activation_relu_1_1.output_10 + 0.06233744111937645 * activation_relu_1_1.output_11 + 0.16030525145048052 * activation_relu_1_1.output_12 + 0.0259334893686136 * activation_relu_1_1.output_13 + 0.19408320988823619 * activation_relu_1_1.output_14 + -0.03958009771773774 * activation_relu_1_1.output_15 AS output_1, -0.1422583716871297 + 0.05778026459179175 * activation_relu_1_1.output_1 + 0.18526624195929928 * activation_relu_1_1.output_2 + 0.15770108884360046 * activation_relu_1_1.output_3 + 0.1349890533075103 * activation_relu_1_1.output_4 + 0.10333683795604298 * activation_relu_1_1.output_5 + -0.06667979614544961 * activation_relu_1_1.output_6 + -0.16383085381360168 * activation_relu_1_1.output_7 + -0.026303657566825484 * activation_relu_1_1.output_8 + 0.26143962138640536 * activation_relu_1_1.output_9 + 0.02334025638958903 * activation_relu_1_1.output_10 + 0.22547924774989286 * activation_relu_1_1.output_11 + -0.0420486272627935 * activation_relu_1_1.output_12 + -0.09189566005637698 * activation_relu_1_1.output_13 + -0.13019884638025725 * activation_relu_1_1.output_14 + -0.07981208671664064 * activation_relu_1_1.output_15 AS output_2, -0.04476026955005754 + 0.17545022239948443 * activation_relu_1_1.output_1 + 0.2947115908681952 * activation_relu_1_1.output_2 + 0.027725314125591982 * activation_relu_1_1.output_3 + -0.057206433112561315 * activation_relu_1_1.output_4 + 0.06740149140157875 * activation_relu_1_1.output_5 + 0.05980357660035989 * activation_relu_1_1.output_6 + -0.15784577761564061 * activation_relu_1_1.output_7 + -0.027792725807995494 * activation_relu_1_1.output_8 + -0.013694638103224282 * activation_relu_1_1.output_9 + -0.17409488398359502 * activation_relu_1_1.output_10 + -0.1413837480688256 * activation_relu_1_1.output_11 + -0.14571614338364447 * activation_relu_1_1.output_12 + -0.09623593321010361 * activation_relu_1_1.output_13 + 0.22005073611649145 * activation_relu_1_1.output_14 + -0.11405175775703616 * activation_relu_1_1.output_15 AS output_3 \n",
      "FROM activation_relu_1_1), \n",
      "layer_3_1 AS \n",
      "(SELECT layer_3.\"KEY\" AS \"KEY\", layer_3.output_1 AS output_1, layer_3.output_2 AS output_2, layer_3.output_3 AS output_3 \n",
      "FROM layer_3), \n",
      "score_soft_max_step1 AS \n",
      "(SELECT layer_3_1.\"KEY\" AS \"KEY\", layer_3_1.output_1 AS \"Score_0\", exp(least(100.0, greatest(-100.0, layer_3_1.output_1))) AS \"exp_Score_0\", layer_3_1.output_2 AS \"Score_1\", exp(least(100.0, greatest(-100.0, layer_3_1.output_2))) AS \"exp_Score_1\", layer_3_1.output_3 AS \"Score_2\", exp(least(100.0, greatest(-100.0, layer_3_1.output_3))) AS \"exp_Score_2\" \n",
      "FROM layer_3_1), \n",
      "score_class_union_soft AS \n",
      "(SELECT soft_scu.\"KEY\" AS \"KEY\", soft_scu.class AS class, soft_scu.\"exp_Score\" AS \"exp_Score\" \n",
      "FROM (SELECT score_soft_max_step1.\"KEY\" AS \"KEY\", 0 AS class, score_soft_max_step1.\"exp_Score_0\" AS \"exp_Score\" \n",
      "FROM score_soft_max_step1 UNION ALL SELECT score_soft_max_step1.\"KEY\" AS \"KEY\", 1 AS class, score_soft_max_step1.\"exp_Score_1\" AS \"exp_Score\" \n",
      "FROM score_soft_max_step1 UNION ALL SELECT score_soft_max_step1.\"KEY\" AS \"KEY\", 2 AS class, score_soft_max_step1.\"exp_Score_2\" AS \"exp_Score\" \n",
      "FROM score_soft_max_step1) AS soft_scu), \n",
      "score_soft_max AS \n",
      "(SELECT score_soft_max_step1.\"KEY\" AS \"KEY\", score_soft_max_step1.\"Score_0\" AS \"Score_0\", score_soft_max_step1.\"exp_Score_0\" AS \"exp_Score_0\", score_soft_max_step1.\"Score_1\" AS \"Score_1\", score_soft_max_step1.\"exp_Score_1\" AS \"exp_Score_1\", score_soft_max_step1.\"Score_2\" AS \"Score_2\", score_soft_max_step1.\"exp_Score_2\" AS \"exp_Score_2\", sum_exp_t.\"KEY_sum\" AS \"KEY_sum\", sum_exp_t.\"sum_ExpScore\" AS \"sum_ExpScore\" \n",
      "FROM score_soft_max_step1 LEFT OUTER JOIN (SELECT score_class_union_soft.\"KEY\" AS \"KEY_sum\", sum(score_class_union_soft.\"exp_Score\") AS \"sum_ExpScore\" \n",
      "FROM score_class_union_soft GROUP BY score_class_union_soft.\"KEY\") AS sum_exp_t ON score_soft_max_step1.\"KEY\" = sum_exp_t.\"KEY_sum\"), \n",
      "layer_softmax AS \n",
      "(SELECT score_soft_max.\"KEY\" AS \"KEY\", score_soft_max.\"exp_Score_0\" / score_soft_max.\"sum_ExpScore\" AS output_1, score_soft_max.\"exp_Score_1\" / score_soft_max.\"sum_ExpScore\" AS output_2, score_soft_max.\"exp_Score_2\" / score_soft_max.\"sum_ExpScore\" AS output_3 \n",
      "FROM score_soft_max), \n",
      "orig_cte AS \n",
      "(SELECT layer_softmax.\"KEY\" AS \"KEY\", CAST(NULL AS FLOAT) AS \"Score_0\", CAST(NULL AS FLOAT) AS \"Score_1\", CAST(NULL AS FLOAT) AS \"Score_2\", layer_softmax.output_1 AS \"Proba_0\", layer_softmax.output_2 AS \"Proba_1\", layer_softmax.output_3 AS \"Proba_2\", CAST(NULL AS FLOAT) AS \"LogProba_0\", CAST(NULL AS FLOAT) AS \"LogProba_1\", CAST(NULL AS FLOAT) AS \"LogProba_2\", CAST(NULL AS BIGINT) AS \"Decision\", CAST(NULL AS FLOAT) AS \"DecisionProba\" \n",
      "FROM layer_softmax), \n",
      "score_class_union AS \n",
      "(SELECT scu.\"KEY_u\" AS \"KEY_u\", scu.class AS class, scu.\"LogProba\" AS \"LogProba\", scu.\"Proba\" AS \"Proba\", scu.\"Score\" AS \"Score\" \n",
      "FROM (SELECT orig_cte.\"KEY\" AS \"KEY_u\", 0 AS class, orig_cte.\"LogProba_0\" AS \"LogProba\", orig_cte.\"Proba_0\" AS \"Proba\", orig_cte.\"Score_0\" AS \"Score\" \n",
      "FROM orig_cte UNION ALL SELECT orig_cte.\"KEY\" AS \"KEY_u\", 1 AS class, orig_cte.\"LogProba_1\" AS \"LogProba\", orig_cte.\"Proba_1\" AS \"Proba\", orig_cte.\"Score_1\" AS \"Score\" \n",
      "FROM orig_cte UNION ALL SELECT orig_cte.\"KEY\" AS \"KEY_u\", 2 AS class, orig_cte.\"LogProba_2\" AS \"LogProba\", orig_cte.\"Proba_2\" AS \"Proba\", orig_cte.\"Score_2\" AS \"Score\" \n",
      "FROM orig_cte) AS scu), \n",
      "score_max AS \n",
      "(SELECT orig_cte.\"KEY\" AS \"KEY\", orig_cte.\"Score_0\" AS \"Score_0\", orig_cte.\"Score_1\" AS \"Score_1\", orig_cte.\"Score_2\" AS \"Score_2\", orig_cte.\"Proba_0\" AS \"Proba_0\", orig_cte.\"Proba_1\" AS \"Proba_1\", orig_cte.\"Proba_2\" AS \"Proba_2\", orig_cte.\"LogProba_0\" AS \"LogProba_0\", orig_cte.\"LogProba_1\" AS \"LogProba_1\", orig_cte.\"LogProba_2\" AS \"LogProba_2\", orig_cte.\"Decision\" AS \"Decision\", orig_cte.\"DecisionProba\" AS \"DecisionProba\", max_select.\"KEY_m\" AS \"KEY_m\", max_select.\"max_Proba\" AS \"max_Proba\" \n",
      "FROM orig_cte LEFT OUTER JOIN (SELECT score_class_union.\"KEY_u\" AS \"KEY_m\", max(score_class_union.\"Proba\") AS \"max_Proba\" \n",
      "FROM score_class_union GROUP BY score_class_union.\"KEY_u\") AS max_select ON orig_cte.\"KEY\" = max_select.\"KEY_m\"), \n",
      "union_with_max AS \n",
      "(SELECT score_class_union.\"KEY_u\" AS \"KEY_u\", score_class_union.class AS class, score_class_union.\"LogProba\" AS \"LogProba\", score_class_union.\"Proba\" AS \"Proba\", score_class_union.\"Score\" AS \"Score\", score_max.\"KEY\" AS \"KEY\", score_max.\"Score_0\" AS \"Score_0\", score_max.\"Score_1\" AS \"Score_1\", score_max.\"Score_2\" AS \"Score_2\", score_max.\"Proba_0\" AS \"Proba_0\", score_max.\"Proba_1\" AS \"Proba_1\", score_max.\"Proba_2\" AS \"Proba_2\", score_max.\"LogProba_0\" AS \"LogProba_0\", score_max.\"LogProba_1\" AS \"LogProba_1\", score_max.\"LogProba_2\" AS \"LogProba_2\", score_max.\"Decision\" AS \"Decision\", score_max.\"DecisionProba\" AS \"DecisionProba\", score_max.\"KEY_m\" AS \"KEY_m\", score_max.\"max_Proba\" AS \"max_Proba\" \n",
      "FROM score_class_union LEFT OUTER JOIN score_max ON score_class_union.\"KEY_u\" = score_max.\"KEY\"), \n",
      "arg_max_cte AS \n",
      "(SELECT score_max.\"KEY\" AS \"KEY\", score_max.\"Score_0\" AS \"Score_0\", score_max.\"Score_1\" AS \"Score_1\", score_max.\"Score_2\" AS \"Score_2\", score_max.\"Proba_0\" AS \"Proba_0\", score_max.\"Proba_1\" AS \"Proba_1\", score_max.\"Proba_2\" AS \"Proba_2\", score_max.\"LogProba_0\" AS \"LogProba_0\", score_max.\"LogProba_1\" AS \"LogProba_1\", score_max.\"LogProba_2\" AS \"LogProba_2\", score_max.\"Decision\" AS \"Decision\", score_max.\"DecisionProba\" AS \"DecisionProba\", score_max.\"KEY_m\" AS \"KEY_m\", score_max.\"max_Proba\" AS \"max_Proba\", \"arg_max_t_Proba\".\"KEY_Proba\" AS \"KEY_Proba\", \"arg_max_t_Proba\".\"arg_max_Proba\" AS \"arg_max_Proba\" \n",
      "FROM score_max LEFT OUTER JOIN (SELECT union_with_max.\"KEY\" AS \"KEY_Proba\", max(union_with_max.class) AS \"arg_max_Proba\" \n",
      "FROM union_with_max \n",
      "WHERE union_with_max.\"max_Proba\" <= union_with_max.\"Proba\" GROUP BY union_with_max.\"KEY\") AS \"arg_max_t_Proba\" ON score_max.\"KEY\" = \"arg_max_t_Proba\".\"KEY_Proba\")\n",
      " SELECT arg_max_cte.\"KEY\" AS \"KEY\", arg_max_cte.\"Score_0\" AS \"Score_0\", arg_max_cte.\"Score_1\" AS \"Score_1\", arg_max_cte.\"Score_2\" AS \"Score_2\", arg_max_cte.\"Proba_0\" AS \"Proba_0\", arg_max_cte.\"Proba_1\" AS \"Proba_1\", arg_max_cte.\"Proba_2\" AS \"Proba_2\", CASE WHEN (arg_max_cte.\"Proba_0\" IS NULL OR arg_max_cte.\"Proba_0\" > 0.0) THEN ln(arg_max_cte.\"Proba_0\") ELSE -1.79769313486231e+308 END AS \"LogProba_0\", CASE WHEN (arg_max_cte.\"Proba_1\" IS NULL OR arg_max_cte.\"Proba_1\" > 0.0) THEN ln(arg_max_cte.\"Proba_1\") ELSE -1.79769313486231e+308 END AS \"LogProba_1\", CASE WHEN (arg_max_cte.\"Proba_2\" IS NULL OR arg_max_cte.\"Proba_2\" > 0.0) THEN ln(arg_max_cte.\"Proba_2\") ELSE -1.79769313486231e+308 END AS \"LogProba_2\", arg_max_cte.\"arg_max_Proba\" AS \"Decision\", arg_max_cte.\"max_Proba\" AS \"DecisionProba\" \n",
      "FROM arg_max_cte\n"
     ]
    }
   ],
   "source": [
    "print(lSQL)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Execute the SQL Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the dataset in a database table\n",
    "\n",
    "\n",
    "import sqlalchemy as sa\n",
    "\n",
    "#engine = sa.create_engine('sqlite://' , echo=False)\n",
    "engine = sa.create_engine(\"postgresql://db:db@localhost/db?port=5432\", echo=False)\n",
    "conn = engine.connect()\n",
    "\n",
    "lTable = pd.DataFrame(iris.data);\n",
    "NC = iris.data.shape[1]\n",
    "lFeatures = ['Feature_' + str(x) for x in range(NC)]\n",
    "lTable.columns = lFeatures\n",
    "lTable['TGT'] = iris.target\n",
    "lTable['KEY'] = range(iris.data.shape[0])\n",
    "lTable.to_sql(\"INPUT_DATA\" , conn,   if_exists='replace', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_output = pd.read_sql(lSQL , conn);\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>KEY</th>\n",
       "      <th>Score_0</th>\n",
       "      <th>Score_1</th>\n",
       "      <th>Score_2</th>\n",
       "      <th>Proba_0</th>\n",
       "      <th>Proba_1</th>\n",
       "      <th>Proba_2</th>\n",
       "      <th>LogProba_0</th>\n",
       "      <th>LogProba_1</th>\n",
       "      <th>LogProba_2</th>\n",
       "      <th>Decision</th>\n",
       "      <th>DecisionProba</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>114</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0.181860</td>\n",
       "      <td>0.453384</td>\n",
       "      <td>0.364756</td>\n",
       "      <td>-1.704520</td>\n",
       "      <td>-0.791015</td>\n",
       "      <td>-1.008527</td>\n",
       "      <td>1</td>\n",
       "      <td>0.453384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>74</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0.202082</td>\n",
       "      <td>0.416369</td>\n",
       "      <td>0.381548</td>\n",
       "      <td>-1.599079</td>\n",
       "      <td>-0.876183</td>\n",
       "      <td>-0.963518</td>\n",
       "      <td>1</td>\n",
       "      <td>0.416369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0.367924</td>\n",
       "      <td>0.330176</td>\n",
       "      <td>0.301901</td>\n",
       "      <td>-0.999879</td>\n",
       "      <td>-1.108131</td>\n",
       "      <td>-1.197658</td>\n",
       "      <td>0</td>\n",
       "      <td>0.367924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>88</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0.225944</td>\n",
       "      <td>0.403559</td>\n",
       "      <td>0.370497</td>\n",
       "      <td>-1.487469</td>\n",
       "      <td>-0.907432</td>\n",
       "      <td>-0.992910</td>\n",
       "      <td>1</td>\n",
       "      <td>0.403559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>25</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0.356184</td>\n",
       "      <td>0.337863</td>\n",
       "      <td>0.305953</td>\n",
       "      <td>-1.032307</td>\n",
       "      <td>-1.085114</td>\n",
       "      <td>-1.184325</td>\n",
       "      <td>0</td>\n",
       "      <td>0.356184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0.364784</td>\n",
       "      <td>0.348123</td>\n",
       "      <td>0.287093</td>\n",
       "      <td>-1.008450</td>\n",
       "      <td>-1.055199</td>\n",
       "      <td>-1.247949</td>\n",
       "      <td>0</td>\n",
       "      <td>0.364784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>48</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0.375260</td>\n",
       "      <td>0.336848</td>\n",
       "      <td>0.287891</td>\n",
       "      <td>-0.980135</td>\n",
       "      <td>-1.088122</td>\n",
       "      <td>-1.245172</td>\n",
       "      <td>0</td>\n",
       "      <td>0.375260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>117</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0.137084</td>\n",
       "      <td>0.456257</td>\n",
       "      <td>0.406659</td>\n",
       "      <td>-1.987164</td>\n",
       "      <td>-0.784699</td>\n",
       "      <td>-0.899780</td>\n",
       "      <td>1</td>\n",
       "      <td>0.456257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>83</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0.182875</td>\n",
       "      <td>0.416904</td>\n",
       "      <td>0.400221</td>\n",
       "      <td>-1.698953</td>\n",
       "      <td>-0.874899</td>\n",
       "      <td>-0.915739</td>\n",
       "      <td>1</td>\n",
       "      <td>0.416904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>105</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0.128363</td>\n",
       "      <td>0.448796</td>\n",
       "      <td>0.422841</td>\n",
       "      <td>-2.052891</td>\n",
       "      <td>-0.801188</td>\n",
       "      <td>-0.860759</td>\n",
       "      <td>1</td>\n",
       "      <td>0.448796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>27</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0.371485</td>\n",
       "      <td>0.336722</td>\n",
       "      <td>0.291793</td>\n",
       "      <td>-0.990246</td>\n",
       "      <td>-1.088498</td>\n",
       "      <td>-1.231712</td>\n",
       "      <td>0</td>\n",
       "      <td>0.371485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>64</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0.237731</td>\n",
       "      <td>0.406999</td>\n",
       "      <td>0.355270</td>\n",
       "      <td>-1.436615</td>\n",
       "      <td>-0.898945</td>\n",
       "      <td>-1.034877</td>\n",
       "      <td>1</td>\n",
       "      <td>0.406999</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     KEY Score_0 Score_1 Score_2   Proba_0   Proba_1   Proba_2  LogProba_0  \\\n",
       "114  114    None    None    None  0.181860  0.453384  0.364756   -1.704520   \n",
       "74    74    None    None    None  0.202082  0.416369  0.381548   -1.599079   \n",
       "9      9    None    None    None  0.367924  0.330176  0.301901   -0.999879   \n",
       "88    88    None    None    None  0.225944  0.403559  0.370497   -1.487469   \n",
       "25    25    None    None    None  0.356184  0.337863  0.305953   -1.032307   \n",
       "5      5    None    None    None  0.364784  0.348123  0.287093   -1.008450   \n",
       "48    48    None    None    None  0.375260  0.336848  0.287891   -0.980135   \n",
       "117  117    None    None    None  0.137084  0.456257  0.406659   -1.987164   \n",
       "83    83    None    None    None  0.182875  0.416904  0.400221   -1.698953   \n",
       "105  105    None    None    None  0.128363  0.448796  0.422841   -2.052891   \n",
       "27    27    None    None    None  0.371485  0.336722  0.291793   -0.990246   \n",
       "64    64    None    None    None  0.237731  0.406999  0.355270   -1.436615   \n",
       "\n",
       "     LogProba_1  LogProba_2  Decision  DecisionProba  \n",
       "114   -0.791015   -1.008527         1       0.453384  \n",
       "74    -0.876183   -0.963518         1       0.416369  \n",
       "9     -1.108131   -1.197658         0       0.367924  \n",
       "88    -0.907432   -0.992910         1       0.403559  \n",
       "25    -1.085114   -1.184325         0       0.356184  \n",
       "5     -1.055199   -1.247949         0       0.364784  \n",
       "48    -1.088122   -1.245172         0       0.375260  \n",
       "117   -0.784699   -0.899780         1       0.456257  \n",
       "83    -0.874899   -0.915739         1       0.416904  \n",
       "105   -0.801188   -0.860759         1       0.448796  \n",
       "27    -1.088498   -1.231712         0       0.371485  \n",
       "64    -0.898945   -1.034877         1       0.406999  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sql_output.sample(12, random_state=1960)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyTorch Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/antoine/.local/lib/python3.6/site-packages/torch/nn/modules/container.py:91: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  input = module(input)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>KEY</th>\n",
       "      <th>Score_0</th>\n",
       "      <th>Score_1</th>\n",
       "      <th>Score_2</th>\n",
       "      <th>Proba_0</th>\n",
       "      <th>Proba_1</th>\n",
       "      <th>Proba_2</th>\n",
       "      <th>LogProba_0</th>\n",
       "      <th>LogProba_1</th>\n",
       "      <th>LogProba_2</th>\n",
       "      <th>Decision</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>114</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.181860</td>\n",
       "      <td>0.453384</td>\n",
       "      <td>0.364756</td>\n",
       "      <td>-1.704520</td>\n",
       "      <td>-0.791015</td>\n",
       "      <td>-1.008527</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>74</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.202082</td>\n",
       "      <td>0.416369</td>\n",
       "      <td>0.381548</td>\n",
       "      <td>-1.599079</td>\n",
       "      <td>-0.876183</td>\n",
       "      <td>-0.963518</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.367924</td>\n",
       "      <td>0.330176</td>\n",
       "      <td>0.301901</td>\n",
       "      <td>-0.999879</td>\n",
       "      <td>-1.108131</td>\n",
       "      <td>-1.197658</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>88</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.225944</td>\n",
       "      <td>0.403559</td>\n",
       "      <td>0.370497</td>\n",
       "      <td>-1.487469</td>\n",
       "      <td>-0.907432</td>\n",
       "      <td>-0.992910</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>25</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.356184</td>\n",
       "      <td>0.337863</td>\n",
       "      <td>0.305953</td>\n",
       "      <td>-1.032307</td>\n",
       "      <td>-1.085114</td>\n",
       "      <td>-1.184325</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.364784</td>\n",
       "      <td>0.348123</td>\n",
       "      <td>0.287093</td>\n",
       "      <td>-1.008450</td>\n",
       "      <td>-1.055199</td>\n",
       "      <td>-1.247949</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>48</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.375260</td>\n",
       "      <td>0.336848</td>\n",
       "      <td>0.287891</td>\n",
       "      <td>-0.980135</td>\n",
       "      <td>-1.088122</td>\n",
       "      <td>-1.245172</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>117</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.137084</td>\n",
       "      <td>0.456257</td>\n",
       "      <td>0.406659</td>\n",
       "      <td>-1.987164</td>\n",
       "      <td>-0.784699</td>\n",
       "      <td>-0.899780</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>83</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.182875</td>\n",
       "      <td>0.416904</td>\n",
       "      <td>0.400221</td>\n",
       "      <td>-1.698953</td>\n",
       "      <td>-0.874899</td>\n",
       "      <td>-0.915739</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>105</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.128363</td>\n",
       "      <td>0.448796</td>\n",
       "      <td>0.422841</td>\n",
       "      <td>-2.052891</td>\n",
       "      <td>-0.801188</td>\n",
       "      <td>-0.860759</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>27</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.371485</td>\n",
       "      <td>0.336722</td>\n",
       "      <td>0.291793</td>\n",
       "      <td>-0.990246</td>\n",
       "      <td>-1.088498</td>\n",
       "      <td>-1.231712</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>64</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.237731</td>\n",
       "      <td>0.406999</td>\n",
       "      <td>0.355270</td>\n",
       "      <td>-1.436615</td>\n",
       "      <td>-0.898945</td>\n",
       "      <td>-1.034877</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     KEY Score_0 Score_1 Score_2   Proba_0   Proba_1   Proba_2  LogProba_0  \\\n",
       "114  114     NaN     NaN     NaN  0.181860  0.453384  0.364756   -1.704520   \n",
       "74    74     NaN     NaN     NaN  0.202082  0.416369  0.381548   -1.599079   \n",
       "9      9     NaN     NaN     NaN  0.367924  0.330176  0.301901   -0.999879   \n",
       "88    88     NaN     NaN     NaN  0.225944  0.403559  0.370497   -1.487469   \n",
       "25    25     NaN     NaN     NaN  0.356184  0.337863  0.305953   -1.032307   \n",
       "5      5     NaN     NaN     NaN  0.364784  0.348123  0.287093   -1.008450   \n",
       "48    48     NaN     NaN     NaN  0.375260  0.336848  0.287891   -0.980135   \n",
       "117  117     NaN     NaN     NaN  0.137084  0.456257  0.406659   -1.987164   \n",
       "83    83     NaN     NaN     NaN  0.182875  0.416904  0.400221   -1.698953   \n",
       "105  105     NaN     NaN     NaN  0.128363  0.448796  0.422841   -2.052891   \n",
       "27    27     NaN     NaN     NaN  0.371485  0.336722  0.291793   -0.990246   \n",
       "64    64     NaN     NaN     NaN  0.237731  0.406999  0.355270   -1.436615   \n",
       "\n",
       "     LogProba_1  LogProba_2  Decision  \n",
       "114   -0.791015   -1.008527         1  \n",
       "74    -0.876183   -0.963518         1  \n",
       "9     -1.108131   -1.197658         0  \n",
       "88    -0.907432   -0.992910         1  \n",
       "25    -1.085114   -1.184325         0  \n",
       "5     -1.055199   -1.247949         0  \n",
       "48    -1.088122   -1.245172         0  \n",
       "117   -0.784699   -0.899780         1  \n",
       "83    -0.874899   -0.915739         1  \n",
       "105   -0.801188   -0.860759         1  \n",
       "27    -1.088498   -1.231712         0  \n",
       "64    -0.898945   -1.034877         1  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pytorch_output = pd.DataFrame()\n",
    "pytorch_output_key = pd.DataFrame(list(range(iris.data.shape[0])), columns=['KEY']);\n",
    "pytorch_output_score = pd.DataFrame(columns=['Score_0', 'Score_1', 'Score_2']);\n",
    "pytorch_output_proba = pd.DataFrame(net.predict_proba(iris.data), columns=['Proba_0', 'Proba_1', 'Proba_2'])\n",
    "pytorch_output = pd.concat([pytorch_output_key, pytorch_output_score, pytorch_output_proba] , axis=1)\n",
    "for class_label in [0, 1, 2]:\n",
    "    pytorch_output['LogProba_' + str(class_label)] = np.log(pytorch_output_proba['Proba_' + str(class_label)])\n",
    "pytorch_output['Decision'] = net.predict(iris.data)\n",
    "pytorch_output.sample(12, random_state=1960)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "format": "column"
   },
   "source": [
    "# Comparing the SQL and PyTorch Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_pytorch_join = pytorch_output.join(sql_output , how='left', on='KEY', lsuffix='_pytorch', rsuffix='_sql')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>KEY_pytorch</th>\n",
       "      <th>Score_0_pytorch</th>\n",
       "      <th>Score_1_pytorch</th>\n",
       "      <th>Score_2_pytorch</th>\n",
       "      <th>Proba_0_pytorch</th>\n",
       "      <th>Proba_1_pytorch</th>\n",
       "      <th>Proba_2_pytorch</th>\n",
       "      <th>LogProba_0_pytorch</th>\n",
       "      <th>LogProba_1_pytorch</th>\n",
       "      <th>LogProba_2_pytorch</th>\n",
       "      <th>...</th>\n",
       "      <th>Score_1_sql</th>\n",
       "      <th>Score_2_sql</th>\n",
       "      <th>Proba_0_sql</th>\n",
       "      <th>Proba_1_sql</th>\n",
       "      <th>Proba_2_sql</th>\n",
       "      <th>LogProba_0_sql</th>\n",
       "      <th>LogProba_1_sql</th>\n",
       "      <th>LogProba_2_sql</th>\n",
       "      <th>Decision_sql</th>\n",
       "      <th>DecisionProba</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.378428</td>\n",
       "      <td>0.334165</td>\n",
       "      <td>0.287407</td>\n",
       "      <td>-0.971730</td>\n",
       "      <td>-1.096119</td>\n",
       "      <td>-1.246857</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0.378428</td>\n",
       "      <td>0.334165</td>\n",
       "      <td>0.287407</td>\n",
       "      <td>-0.971730</td>\n",
       "      <td>-1.096119</td>\n",
       "      <td>-1.246857</td>\n",
       "      <td>0</td>\n",
       "      <td>0.378428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.367990</td>\n",
       "      <td>0.334633</td>\n",
       "      <td>0.297376</td>\n",
       "      <td>-0.999698</td>\n",
       "      <td>-1.094720</td>\n",
       "      <td>-1.212758</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0.367990</td>\n",
       "      <td>0.334633</td>\n",
       "      <td>0.297376</td>\n",
       "      <td>-0.999698</td>\n",
       "      <td>-1.094720</td>\n",
       "      <td>-1.212758</td>\n",
       "      <td>0</td>\n",
       "      <td>0.367990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.382634</td>\n",
       "      <td>0.329002</td>\n",
       "      <td>0.288365</td>\n",
       "      <td>-0.960677</td>\n",
       "      <td>-1.111692</td>\n",
       "      <td>-1.243530</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0.382634</td>\n",
       "      <td>0.329002</td>\n",
       "      <td>0.288365</td>\n",
       "      <td>-0.960677</td>\n",
       "      <td>-1.111692</td>\n",
       "      <td>-1.243530</td>\n",
       "      <td>0</td>\n",
       "      <td>0.382634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.371644</td>\n",
       "      <td>0.329940</td>\n",
       "      <td>0.298416</td>\n",
       "      <td>-0.989819</td>\n",
       "      <td>-1.108844</td>\n",
       "      <td>-1.209266</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0.371644</td>\n",
       "      <td>0.329940</td>\n",
       "      <td>0.298416</td>\n",
       "      <td>-0.989819</td>\n",
       "      <td>-1.108844</td>\n",
       "      <td>-1.209266</td>\n",
       "      <td>0</td>\n",
       "      <td>0.371644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.383270</td>\n",
       "      <td>0.331753</td>\n",
       "      <td>0.284976</td>\n",
       "      <td>-0.959015</td>\n",
       "      <td>-1.103363</td>\n",
       "      <td>-1.255349</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0.383270</td>\n",
       "      <td>0.331753</td>\n",
       "      <td>0.284976</td>\n",
       "      <td>-0.959015</td>\n",
       "      <td>-1.103363</td>\n",
       "      <td>-1.255349</td>\n",
       "      <td>0</td>\n",
       "      <td>0.383270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.364784</td>\n",
       "      <td>0.348123</td>\n",
       "      <td>0.287093</td>\n",
       "      <td>-1.008450</td>\n",
       "      <td>-1.055199</td>\n",
       "      <td>-1.247949</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0.364784</td>\n",
       "      <td>0.348123</td>\n",
       "      <td>0.287093</td>\n",
       "      <td>-1.008450</td>\n",
       "      <td>-1.055199</td>\n",
       "      <td>-1.247949</td>\n",
       "      <td>0</td>\n",
       "      <td>0.364784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.382392</td>\n",
       "      <td>0.331352</td>\n",
       "      <td>0.286255</td>\n",
       "      <td>-0.961308</td>\n",
       "      <td>-1.104574</td>\n",
       "      <td>-1.250871</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0.382392</td>\n",
       "      <td>0.331352</td>\n",
       "      <td>0.286255</td>\n",
       "      <td>-0.961308</td>\n",
       "      <td>-1.104574</td>\n",
       "      <td>-1.250871</td>\n",
       "      <td>0</td>\n",
       "      <td>0.382392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.372504</td>\n",
       "      <td>0.334211</td>\n",
       "      <td>0.293285</td>\n",
       "      <td>-0.987508</td>\n",
       "      <td>-1.095983</td>\n",
       "      <td>-1.226609</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0.372504</td>\n",
       "      <td>0.334211</td>\n",
       "      <td>0.293285</td>\n",
       "      <td>-0.987508</td>\n",
       "      <td>-1.095983</td>\n",
       "      <td>-1.226609</td>\n",
       "      <td>0</td>\n",
       "      <td>0.372504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.374778</td>\n",
       "      <td>0.327310</td>\n",
       "      <td>0.297912</td>\n",
       "      <td>-0.981421</td>\n",
       "      <td>-1.116848</td>\n",
       "      <td>-1.210958</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0.374778</td>\n",
       "      <td>0.327310</td>\n",
       "      <td>0.297912</td>\n",
       "      <td>-0.981421</td>\n",
       "      <td>-1.116848</td>\n",
       "      <td>-1.210958</td>\n",
       "      <td>0</td>\n",
       "      <td>0.374778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.367924</td>\n",
       "      <td>0.330176</td>\n",
       "      <td>0.301901</td>\n",
       "      <td>-0.999879</td>\n",
       "      <td>-1.108131</td>\n",
       "      <td>-1.197658</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0.367924</td>\n",
       "      <td>0.330176</td>\n",
       "      <td>0.301901</td>\n",
       "      <td>-0.999879</td>\n",
       "      <td>-1.108131</td>\n",
       "      <td>-1.197658</td>\n",
       "      <td>0</td>\n",
       "      <td>0.367924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.373312</td>\n",
       "      <td>0.338488</td>\n",
       "      <td>0.288201</td>\n",
       "      <td>-0.985342</td>\n",
       "      <td>-1.083268</td>\n",
       "      <td>-1.244098</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0.373312</td>\n",
       "      <td>0.338488</td>\n",
       "      <td>0.288201</td>\n",
       "      <td>-0.985342</td>\n",
       "      <td>-1.083268</td>\n",
       "      <td>-1.244098</td>\n",
       "      <td>0</td>\n",
       "      <td>0.373312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.371379</td>\n",
       "      <td>0.331856</td>\n",
       "      <td>0.296765</td>\n",
       "      <td>-0.990533</td>\n",
       "      <td>-1.103053</td>\n",
       "      <td>-1.214815</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0.371379</td>\n",
       "      <td>0.331856</td>\n",
       "      <td>0.296765</td>\n",
       "      <td>-0.990533</td>\n",
       "      <td>-1.103053</td>\n",
       "      <td>-1.214815</td>\n",
       "      <td>0</td>\n",
       "      <td>0.371379</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    KEY_pytorch Score_0_pytorch Score_1_pytorch Score_2_pytorch  \\\n",
       "0             0             NaN             NaN             NaN   \n",
       "1             1             NaN             NaN             NaN   \n",
       "2             2             NaN             NaN             NaN   \n",
       "3             3             NaN             NaN             NaN   \n",
       "4             4             NaN             NaN             NaN   \n",
       "5             5             NaN             NaN             NaN   \n",
       "6             6             NaN             NaN             NaN   \n",
       "7             7             NaN             NaN             NaN   \n",
       "8             8             NaN             NaN             NaN   \n",
       "9             9             NaN             NaN             NaN   \n",
       "10           10             NaN             NaN             NaN   \n",
       "11           11             NaN             NaN             NaN   \n",
       "\n",
       "    Proba_0_pytorch  Proba_1_pytorch  Proba_2_pytorch  LogProba_0_pytorch  \\\n",
       "0          0.378428         0.334165         0.287407           -0.971730   \n",
       "1          0.367990         0.334633         0.297376           -0.999698   \n",
       "2          0.382634         0.329002         0.288365           -0.960677   \n",
       "3          0.371644         0.329940         0.298416           -0.989819   \n",
       "4          0.383270         0.331753         0.284976           -0.959015   \n",
       "5          0.364784         0.348123         0.287093           -1.008450   \n",
       "6          0.382392         0.331352         0.286255           -0.961308   \n",
       "7          0.372504         0.334211         0.293285           -0.987508   \n",
       "8          0.374778         0.327310         0.297912           -0.981421   \n",
       "9          0.367924         0.330176         0.301901           -0.999879   \n",
       "10         0.373312         0.338488         0.288201           -0.985342   \n",
       "11         0.371379         0.331856         0.296765           -0.990533   \n",
       "\n",
       "    LogProba_1_pytorch  LogProba_2_pytorch      ...        Score_1_sql  \\\n",
       "0            -1.096119           -1.246857      ...               None   \n",
       "1            -1.094720           -1.212758      ...               None   \n",
       "2            -1.111692           -1.243530      ...               None   \n",
       "3            -1.108844           -1.209266      ...               None   \n",
       "4            -1.103363           -1.255349      ...               None   \n",
       "5            -1.055199           -1.247949      ...               None   \n",
       "6            -1.104574           -1.250871      ...               None   \n",
       "7            -1.095983           -1.226609      ...               None   \n",
       "8            -1.116848           -1.210958      ...               None   \n",
       "9            -1.108131           -1.197658      ...               None   \n",
       "10           -1.083268           -1.244098      ...               None   \n",
       "11           -1.103053           -1.214815      ...               None   \n",
       "\n",
       "    Score_2_sql Proba_0_sql Proba_1_sql Proba_2_sql  LogProba_0_sql  \\\n",
       "0          None    0.378428    0.334165    0.287407       -0.971730   \n",
       "1          None    0.367990    0.334633    0.297376       -0.999698   \n",
       "2          None    0.382634    0.329002    0.288365       -0.960677   \n",
       "3          None    0.371644    0.329940    0.298416       -0.989819   \n",
       "4          None    0.383270    0.331753    0.284976       -0.959015   \n",
       "5          None    0.364784    0.348123    0.287093       -1.008450   \n",
       "6          None    0.382392    0.331352    0.286255       -0.961308   \n",
       "7          None    0.372504    0.334211    0.293285       -0.987508   \n",
       "8          None    0.374778    0.327310    0.297912       -0.981421   \n",
       "9          None    0.367924    0.330176    0.301901       -0.999879   \n",
       "10         None    0.373312    0.338488    0.288201       -0.985342   \n",
       "11         None    0.371379    0.331856    0.296765       -0.990533   \n",
       "\n",
       "    LogProba_1_sql  LogProba_2_sql  Decision_sql  DecisionProba  \n",
       "0        -1.096119       -1.246857             0       0.378428  \n",
       "1        -1.094720       -1.212758             0       0.367990  \n",
       "2        -1.111692       -1.243530             0       0.382634  \n",
       "3        -1.108844       -1.209266             0       0.371644  \n",
       "4        -1.103363       -1.255349             0       0.383270  \n",
       "5        -1.055199       -1.247949             0       0.364784  \n",
       "6        -1.104574       -1.250871             0       0.382392  \n",
       "7        -1.095983       -1.226609             0       0.372504  \n",
       "8        -1.116848       -1.210958             0       0.374778  \n",
       "9        -1.108131       -1.197658             0       0.367924  \n",
       "10       -1.083268       -1.244098             0       0.373312  \n",
       "11       -1.103053       -1.214815             0       0.371379  \n",
       "\n",
       "[12 rows x 23 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sql_pytorch_join.head(12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>KEY_pytorch</th>\n",
       "      <th>Score_0_pytorch</th>\n",
       "      <th>Score_1_pytorch</th>\n",
       "      <th>Score_2_pytorch</th>\n",
       "      <th>Proba_0_pytorch</th>\n",
       "      <th>Proba_1_pytorch</th>\n",
       "      <th>Proba_2_pytorch</th>\n",
       "      <th>LogProba_0_pytorch</th>\n",
       "      <th>LogProba_1_pytorch</th>\n",
       "      <th>LogProba_2_pytorch</th>\n",
       "      <th>...</th>\n",
       "      <th>Score_1_sql</th>\n",
       "      <th>Score_2_sql</th>\n",
       "      <th>Proba_0_sql</th>\n",
       "      <th>Proba_1_sql</th>\n",
       "      <th>Proba_2_sql</th>\n",
       "      <th>LogProba_0_sql</th>\n",
       "      <th>LogProba_1_sql</th>\n",
       "      <th>LogProba_2_sql</th>\n",
       "      <th>Decision_sql</th>\n",
       "      <th>DecisionProba</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>0 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [KEY_pytorch, Score_0_pytorch, Score_1_pytorch, Score_2_pytorch, Proba_0_pytorch, Proba_1_pytorch, Proba_2_pytorch, LogProba_0_pytorch, LogProba_1_pytorch, LogProba_2_pytorch, Decision_pytorch, KEY_sql, Score_0_sql, Score_1_sql, Score_2_sql, Proba_0_sql, Proba_1_sql, Proba_2_sql, LogProba_0_sql, LogProba_1_sql, LogProba_2_sql, Decision_sql, DecisionProba]\n",
       "Index: []\n",
       "\n",
       "[0 rows x 23 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "condition = (sql_pytorch_join.Decision_sql != sql_pytorch_join.Decision_pytorch)\n",
    "sql_pytorch_join[condition]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert(sql_pytorch_join[condition].shape[0] == 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
